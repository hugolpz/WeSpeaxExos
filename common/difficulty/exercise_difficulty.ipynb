{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import class to calculate exercise difficulty\n",
    "from exercise_difficulty import Difficulty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arabic exercise difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import exercise dataset\n",
    "ar_exo_df = pd.read_excel(\"../../ar/Arabic_Exercises.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define exercise objectives\n",
    "word_exo_objs = [\"\"] # objectives of word exercises\n",
    "sent_exo_objs = [\"Useful Sentences\", \"Grammar\", \"Vocabulary\"] # objectives of sentence exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Puntu\\WeSpeaxExos\\common\\difficulty\\exercise_difficulty.py:229: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sent_exo_df[\"Length_sentence\"] = sent_exo_df[\"Full_sentence\"].apply(lambda text: self.sentence_length(str(text)))\n",
      "c:\\Users\\Khushi\\anaconda3\\envs\\year_4\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "d:\\Puntu\\WeSpeaxExos\\common\\difficulty\\exercise_difficulty.py:232: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sent_exo_df[\"Score_sentence_average\"] = sent_exo_df[\"Right_answer\"].apply(lambda text: self.find_wSavg(str(text)))\n",
      "d:\\Puntu\\WeSpeaxExos\\common\\difficulty\\exercise_difficulty.py:235: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sent_exo_df[\"Frequency_rarest_word\"] = sent_exo_df[\"Right_answer\"].apply(lambda text: self.find_wSRarest(str(text)))\n",
      "d:\\Puntu\\WeSpeaxExos\\common\\difficulty\\exercise_difficulty.py:238: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sent_exo_df[\"Score_sentence\"] = sent_exo_df[\"Full_sentence\"].apply(lambda text: self.find_SScore(str(text)))\n",
      "d:\\Puntu\\WeSpeaxExos\\common\\difficulty\\exercise_difficulty.py:242: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sent_exo_df[\"Difficulty\"] = list(map(self.find_difficulty_level, quantile_ranks))\n",
      "d:\\Puntu\\WeSpeaxExos\\common\\difficulty\\exercise_difficulty.py:244: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  return word_exo_df.append(sent_exo_df,ignore_index = True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exo_type_id</th>\n",
       "      <th>Exo_type</th>\n",
       "      <th>Exo_objective</th>\n",
       "      <th>Exo_focus</th>\n",
       "      <th>Exo_id</th>\n",
       "      <th>Source_format</th>\n",
       "      <th>Target_format</th>\n",
       "      <th>Source_sentence_id</th>\n",
       "      <th>Source_word_id</th>\n",
       "      <th>Source_lang</th>\n",
       "      <th>...</th>\n",
       "      <th>dist_3</th>\n",
       "      <th>Propositions</th>\n",
       "      <th>Explanation</th>\n",
       "      <th>Difficulty</th>\n",
       "      <th>Remediation</th>\n",
       "      <th>Full_sentence_wthsyll</th>\n",
       "      <th>Length_sentence</th>\n",
       "      <th>Score_sentence_average</th>\n",
       "      <th>Frequency_rarest_word</th>\n",
       "      <th>Score_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Cloze_Test_+_MCQ</td>\n",
       "      <td>Grammar</td>\n",
       "      <td>Verb_conjugation</td>\n",
       "      <td>1</td>\n",
       "      <td>Text</td>\n",
       "      <td>Text</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>French</td>\n",
       "      <td>...</td>\n",
       "      <td>كَانَ</td>\n",
       "      <td>كَانَ-يَكُنْ-تَكَانَانِ-تَكَانُونَ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>لم يكن لشره حدودا.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>2.45</td>\n",
       "      <td>26.191964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Cloze_Test_+_MCQ</td>\n",
       "      <td>Grammar</td>\n",
       "      <td>Verb_conjugation</td>\n",
       "      <td>2</td>\n",
       "      <td>Text</td>\n",
       "      <td>Text</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>French</td>\n",
       "      <td>...</td>\n",
       "      <td>أَثَرَا</td>\n",
       "      <td>نَأْثَرُ-أَثّرَتْ-تَأْثَرِينَ-أَثَرَا</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>أناقته أثرت في الحضور.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.091429</td>\n",
       "      <td>3.82</td>\n",
       "      <td>28.955357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Cloze_Test_+_MCQ</td>\n",
       "      <td>Grammar</td>\n",
       "      <td>Verb_conjugation</td>\n",
       "      <td>3</td>\n",
       "      <td>Text</td>\n",
       "      <td>Text</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>French</td>\n",
       "      <td>...</td>\n",
       "      <td>يَتَمُّونَ</td>\n",
       "      <td>تَمَمْتُنَّ-يَتَمُّونَ-تَمَّ-تَمَمْنَا</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>جودة عمله تم الاعتراف بها من طرف لجنة التحكيم.</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.264286</td>\n",
       "      <td>1.85</td>\n",
       "      <td>27.975143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Cloze_Test_+_MCQ</td>\n",
       "      <td>Grammar</td>\n",
       "      <td>Verb_conjugation</td>\n",
       "      <td>4</td>\n",
       "      <td>Text</td>\n",
       "      <td>Text</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>French</td>\n",
       "      <td>...</td>\n",
       "      <td>يَنْتَشِرَانِ</td>\n",
       "      <td>انتشَرَتْ-اِنْتَشَرْتُمَا-يَنْتَشِرَانِ-تَنْتَ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>كمية مهمة من البترول انتشرت في البحر.</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.572857</td>\n",
       "      <td>3.67</td>\n",
       "      <td>24.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Cloze_Test_+_MCQ</td>\n",
       "      <td>Grammar</td>\n",
       "      <td>Verb_conjugation</td>\n",
       "      <td>5</td>\n",
       "      <td>Text</td>\n",
       "      <td>Text</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>French</td>\n",
       "      <td>...</td>\n",
       "      <td>تَحْضَرْنَ</td>\n",
       "      <td>تُحَضِّرُ-تَحْضَرْنَ-تَحْضَرِينَ-حَضَرْتُمَا</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>أمه تحضر فطائر جد لذيذة.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.140000</td>\n",
       "      <td>3.99</td>\n",
       "      <td>25.004729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Exo_type_id          Exo_type Exo_objective         Exo_focus  Exo_id  \\\n",
       "0            0  Cloze_Test_+_MCQ       Grammar  Verb_conjugation       1   \n",
       "1            0  Cloze_Test_+_MCQ       Grammar  Verb_conjugation       2   \n",
       "2            0  Cloze_Test_+_MCQ       Grammar  Verb_conjugation       3   \n",
       "3            0  Cloze_Test_+_MCQ       Grammar  Verb_conjugation       4   \n",
       "4            0  Cloze_Test_+_MCQ       Grammar  Verb_conjugation       5   \n",
       "\n",
       "  Source_format Target_format  Source_sentence_id  Source_word_id Source_lang  \\\n",
       "0          Text          Text                   6               0      French   \n",
       "1          Text          Text                   7               0      French   \n",
       "2          Text          Text                  11               0      French   \n",
       "3          Text          Text                  12               0      French   \n",
       "4          Text          Text                  15               0      French   \n",
       "\n",
       "   ...         dist_3                                       Propositions  \\\n",
       "0  ...          كَانَ                 كَانَ-يَكُنْ-تَكَانَانِ-تَكَانُونَ   \n",
       "1  ...        أَثَرَا              نَأْثَرُ-أَثّرَتْ-تَأْثَرِينَ-أَثَرَا   \n",
       "2  ...     يَتَمُّونَ             تَمَمْتُنَّ-يَتَمُّونَ-تَمَّ-تَمَمْنَا   \n",
       "3  ...  يَنْتَشِرَانِ  انتشَرَتْ-اِنْتَشَرْتُمَا-يَنْتَشِرَانِ-تَنْتَ...   \n",
       "4  ...     تَحْضَرْنَ       تُحَضِّرُ-تَحْضَرْنَ-تَحْضَرِينَ-حَضَرْتُمَا   \n",
       "\n",
       "  Explanation Difficulty Remediation  \\\n",
       "0         NaN         B1         NaN   \n",
       "1         NaN         B2         NaN   \n",
       "2         NaN         B1         NaN   \n",
       "3         NaN         B1         NaN   \n",
       "4         NaN         B1         NaN   \n",
       "\n",
       "                            Full_sentence_wthsyll Length_sentence  \\\n",
       "0                              لم يكن لشره حدودا.             4.0   \n",
       "1                          أناقته أثرت في الحضور.             4.0   \n",
       "2  جودة عمله تم الاعتراف بها من طرف لجنة التحكيم.             9.0   \n",
       "3           كمية مهمة من البترول انتشرت في البحر.             7.0   \n",
       "4                        أمه تحضر فطائر جد لذيذة.             5.0   \n",
       "\n",
       "  Score_sentence_average Frequency_rarest_word  Score_sentence  \n",
       "0               0.525000                  2.45       26.191964  \n",
       "1               1.091429                  3.82       28.955357  \n",
       "2               0.264286                  1.85       27.975143  \n",
       "3               1.572857                  3.67       24.130000  \n",
       "4               1.140000                  3.99       25.004729  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define difficulty class\n",
    "difficulty_class = Difficulty(exo_df = ar_exo_df, language = \"ar\", word_exo_objs = word_exo_objs, sent_exo_objs = sent_exo_objs)\n",
    "\n",
    "# call function to calculate exercise difficulty from class object\n",
    "complete_exo_ar_df = difficulty_class.find_all_scores()\n",
    "\n",
    "complete_exo_ar_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the exercise dataset with their respective difficulty scores as an excel file\n",
    "complete_exo_ar_df.to_excel(\"../../ar/Arabic_Exercises_with_Difficulty.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English exercise difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import exercise dataset\n",
    "en_exo_df = pd.read_excel(\"../../en/English_Exercises.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define exercise objectives\n",
    "word_exo_objs = [\"Learning_Vocabulary\"] # objectives of word exercises\n",
    "sent_exo_objs = [\"Useful Sentences\", \"Grammar\"] # objectives of sentence exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Puntu\\WeSpeaxExos\\common\\difficulty\\exercise_difficulty.py:221: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_exo_df[\"Score_sentence\"] = word_exo_df[\"Full_sentence\"].apply(lambda text: self.find_wSavg(str(text)))\n",
      "d:\\Puntu\\WeSpeaxExos\\common\\difficulty\\exercise_difficulty.py:225: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_exo_df[\"Difficulty\"] = list(map(self.find_difficulty_level, quantile_ranks))\n",
      "d:\\Puntu\\WeSpeaxExos\\common\\difficulty\\exercise_difficulty.py:229: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sent_exo_df[\"Length_sentence\"] = sent_exo_df[\"Full_sentence\"].apply(lambda text: self.sentence_length(str(text)))\n",
      "c:\\Users\\Khushi\\anaconda3\\envs\\year_4\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "d:\\Puntu\\WeSpeaxExos\\common\\difficulty\\exercise_difficulty.py:232: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sent_exo_df[\"Score_sentence_average\"] = sent_exo_df[\"Right_answer\"].apply(lambda text: self.find_wSavg(str(text)))\n",
      "d:\\Puntu\\WeSpeaxExos\\common\\difficulty\\exercise_difficulty.py:235: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sent_exo_df[\"Frequency_rarest_word\"] = sent_exo_df[\"Right_answer\"].apply(lambda text: self.find_wSRarest(str(text)))\n",
      "d:\\Puntu\\WeSpeaxExos\\common\\difficulty\\exercise_difficulty.py:238: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sent_exo_df[\"Score_sentence\"] = sent_exo_df[\"Full_sentence\"].apply(lambda text: self.find_SScore(str(text)))\n",
      "d:\\Puntu\\WeSpeaxExos\\common\\difficulty\\exercise_difficulty.py:242: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sent_exo_df[\"Difficulty\"] = list(map(self.find_difficulty_level, quantile_ranks))\n",
      "d:\\Puntu\\WeSpeaxExos\\common\\difficulty\\exercise_difficulty.py:244: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  return word_exo_df.append(sent_exo_df,ignore_index = True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exo_type_id</th>\n",
       "      <th>Exo_type</th>\n",
       "      <th>Exo_objective</th>\n",
       "      <th>Exo_focus</th>\n",
       "      <th>Exo_id</th>\n",
       "      <th>Source_format</th>\n",
       "      <th>Target_format</th>\n",
       "      <th>Source_sentence_id</th>\n",
       "      <th>Source_word_id</th>\n",
       "      <th>Source_lang</th>\n",
       "      <th>...</th>\n",
       "      <th>Dist_1</th>\n",
       "      <th>Dist_2</th>\n",
       "      <th>Dist_3</th>\n",
       "      <th>Explanation</th>\n",
       "      <th>Difficulty</th>\n",
       "      <th>Remediation</th>\n",
       "      <th>Score_sentence</th>\n",
       "      <th>Length_sentence</th>\n",
       "      <th>Score_sentence_average</th>\n",
       "      <th>Frequency_rarest_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>Flashcards</td>\n",
       "      <td>Learning_Vocabulary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>text</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>French</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Flashcards</td>\n",
       "      <td>Learning_Vocabulary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>text</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>French</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.819444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>Flashcards</td>\n",
       "      <td>Learning_Vocabulary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>text</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>French</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.221111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>Flashcards</td>\n",
       "      <td>Learning_Vocabulary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>text</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>French</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.536111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>Flashcards</td>\n",
       "      <td>Learning_Vocabulary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>text</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>French</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Exo_type_id    Exo_type        Exo_objective Exo_focus  Exo_id  \\\n",
       "0           10  Flashcards  Learning_Vocabulary       NaN       1   \n",
       "1           10  Flashcards  Learning_Vocabulary       NaN       2   \n",
       "2           10  Flashcards  Learning_Vocabulary       NaN       3   \n",
       "3           10  Flashcards  Learning_Vocabulary       NaN       4   \n",
       "4           10  Flashcards  Learning_Vocabulary       NaN       5   \n",
       "\n",
       "  Source_format Target_format  Source_sentence_id  Source_word_id Source_lang  \\\n",
       "0          text          text                 NaN             1.0      French   \n",
       "1          text          text                 NaN             2.0      French   \n",
       "2          text          text                 NaN             3.0      French   \n",
       "3          text          text                 NaN             4.0      French   \n",
       "4          text          text                 NaN             5.0      French   \n",
       "\n",
       "   ... Dist_1 Dist_2 Dist_3 Explanation Difficulty Remediation Score_sentence  \\\n",
       "0  ...    NaN    NaN    NaN         NaN         B2         NaN       1.083333   \n",
       "1  ...    NaN    NaN    NaN         NaN         B1         NaN       0.819444   \n",
       "2  ...    NaN    NaN    NaN         NaN         C1         NaN       1.221111   \n",
       "3  ...    NaN    NaN    NaN         NaN         C1         NaN       2.536111   \n",
       "4  ...    NaN    NaN    NaN         NaN         C1         NaN       1.777778   \n",
       "\n",
       "  Length_sentence  Score_sentence_average Frequency_rarest_word  \n",
       "0             NaN                     NaN                   NaN  \n",
       "1             NaN                     NaN                   NaN  \n",
       "2             NaN                     NaN                   NaN  \n",
       "3             NaN                     NaN                   NaN  \n",
       "4             NaN                     NaN                   NaN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define difficulty class\n",
    "difficulty_class = Difficulty(exo_df = en_exo_df, language = \"en\", word_exo_objs = word_exo_objs, sent_exo_objs = sent_exo_objs)\n",
    "\n",
    "# call function to calculate exercise difficulty from class object\n",
    "complete_exo_en_df = difficulty_class.find_all_scores()\n",
    "\n",
    "complete_exo_en_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the exercise dataset with their respective difficulty scores as an excel file\n",
    "complete_exo_en_df.to_excel(\"../../en/English_Exercises_with_Difficulty.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hindi exercise difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import exercise dataset\n",
    "hi_exo_df = pd.read_excel(\"../../hi/Hindi_Exercises.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define exercise objectives\n",
    "word_exo_objs = [\"Learning_Vocabulary\"] # objectives of word exercises\n",
    "sent_exo_objs = [\"Useful Sentences\", \"Grammar\"] # objectives of sentence exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Puntu\\WeSpeaxExos\\common\\difficulty\\exercise_difficulty.py:221: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_exo_df[\"Score_sentence\"] = word_exo_df[\"Full_sentence\"].apply(lambda text: self.find_wSavg(str(text)))\n",
      "d:\\Puntu\\WeSpeaxExos\\common\\difficulty\\exercise_difficulty.py:225: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_exo_df[\"Difficulty\"] = list(map(self.find_difficulty_level, quantile_ranks))\n",
      "d:\\Puntu\\WeSpeaxExos\\common\\difficulty\\exercise_difficulty.py:229: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sent_exo_df[\"Length_sentence\"] = sent_exo_df[\"Full_sentence\"].apply(lambda text: self.sentence_length(str(text)))\n",
      "c:\\Users\\Khushi\\anaconda3\\envs\\year_4\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "d:\\Puntu\\WeSpeaxExos\\common\\difficulty\\exercise_difficulty.py:232: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sent_exo_df[\"Score_sentence_average\"] = sent_exo_df[\"Right_answer\"].apply(lambda text: self.find_wSavg(str(text)))\n",
      "d:\\Puntu\\WeSpeaxExos\\common\\difficulty\\exercise_difficulty.py:235: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sent_exo_df[\"Frequency_rarest_word\"] = sent_exo_df[\"Right_answer\"].apply(lambda text: self.find_wSRarest(str(text)))\n",
      "d:\\Puntu\\WeSpeaxExos\\common\\difficulty\\exercise_difficulty.py:238: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sent_exo_df[\"Score_sentence\"] = sent_exo_df[\"Full_sentence\"].apply(lambda text: self.find_SScore(str(text)))\n",
      "d:\\Puntu\\WeSpeaxExos\\common\\difficulty\\exercise_difficulty.py:242: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sent_exo_df[\"Difficulty\"] = list(map(self.find_difficulty_level, quantile_ranks))\n",
      "d:\\Puntu\\WeSpeaxExos\\common\\difficulty\\exercise_difficulty.py:244: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  return word_exo_df.append(sent_exo_df,ignore_index = True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exo_type_id</th>\n",
       "      <th>Exo_type</th>\n",
       "      <th>Exo_objective</th>\n",
       "      <th>Exo_focus</th>\n",
       "      <th>Exo_id</th>\n",
       "      <th>Source_format</th>\n",
       "      <th>Target_format</th>\n",
       "      <th>Source_sentence_id</th>\n",
       "      <th>Source_word_id</th>\n",
       "      <th>Source_lang</th>\n",
       "      <th>...</th>\n",
       "      <th>Dist_1</th>\n",
       "      <th>Dist_2</th>\n",
       "      <th>Dist_3</th>\n",
       "      <th>Explanation</th>\n",
       "      <th>Difficulty</th>\n",
       "      <th>Remediation</th>\n",
       "      <th>Score_sentence</th>\n",
       "      <th>Length_sentence</th>\n",
       "      <th>Score_sentence_average</th>\n",
       "      <th>Frequency_rarest_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>Flashcards</td>\n",
       "      <td>Learning_Vocabulary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>text</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>French</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Flashcards</td>\n",
       "      <td>Learning_Vocabulary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>text</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>French</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.401304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>Flashcards</td>\n",
       "      <td>Learning_Vocabulary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>text</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>French</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.381739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>Flashcards</td>\n",
       "      <td>Learning_Vocabulary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>text</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>French</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.457826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>Flashcards</td>\n",
       "      <td>Learning_Vocabulary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>text</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>French</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.434783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Exo_type_id    Exo_type        Exo_objective Exo_focus  Exo_id  \\\n",
       "0           10  Flashcards  Learning_Vocabulary       NaN       1   \n",
       "1           10  Flashcards  Learning_Vocabulary       NaN       2   \n",
       "2           10  Flashcards  Learning_Vocabulary       NaN       3   \n",
       "3           10  Flashcards  Learning_Vocabulary       NaN       4   \n",
       "4           10  Flashcards  Learning_Vocabulary       NaN       5   \n",
       "\n",
       "  Source_format Target_format  Source_sentence_id  Source_word_id Source_lang  \\\n",
       "0          text          text                 NaN             2.0      French   \n",
       "1          text          text                 NaN             3.0      French   \n",
       "2          text          text                 NaN             4.0      French   \n",
       "3          text          text                 NaN             5.0      French   \n",
       "4          text          text                 NaN             6.0      French   \n",
       "\n",
       "   ... Dist_1 Dist_2 Dist_3 Explanation Difficulty Remediation Score_sentence  \\\n",
       "0  ...    NaN    NaN    NaN         NaN         A1         NaN       0.226957   \n",
       "1  ...    NaN    NaN    NaN         NaN         C1         NaN       1.401304   \n",
       "2  ...    NaN    NaN    NaN         NaN         C1         NaN       1.381739   \n",
       "3  ...    NaN    NaN    NaN         NaN         A2         NaN       0.457826   \n",
       "4  ...    NaN    NaN    NaN         NaN         C1         NaN       2.434783   \n",
       "\n",
       "  Length_sentence  Score_sentence_average Frequency_rarest_word  \n",
       "0             NaN                     NaN                   NaN  \n",
       "1             NaN                     NaN                   NaN  \n",
       "2             NaN                     NaN                   NaN  \n",
       "3             NaN                     NaN                   NaN  \n",
       "4             NaN                     NaN                   NaN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define difficulty class\n",
    "difficulty_class = Difficulty(exo_df = hi_exo_df, language = \"hi\", word_exo_objs = word_exo_objs, sent_exo_objs = sent_exo_objs)\n",
    "\n",
    "# call function to calculate exercise difficulty from class object\n",
    "complete_exo_hi_df = difficulty_class.find_all_scores()\n",
    "\n",
    "complete_exo_hi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the exercise dataset with their respective difficulty scores as an excel file\n",
    "complete_exo_hi_df.to_excel(\"../../hi/Hindi_Exercises_with_Difficulty.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('year_4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2dbc6a3e06803adbf086ce64bb7fe7554f6a053388168c89795f9a02e75d57e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
